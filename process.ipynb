{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "# 打开源文件\n",
    "for name in range(2000,2021):\n",
    "    fire_gdf = gpd.read_file('Pro_vic/'+ str(name)+'.shp')\n",
    "    # 清洗confidence为0的虚假火灾点\n",
    "    st = fire_gdf[fire_gdf['confidence'] !=0]\n",
    "    # 保留发生月份在1，2，12, 11月的火灾点\n",
    "    st['acq_date']=st['acq_date'].apply(lambda x: datetime.strptime(x, \"%Y-%m-%d\"))\n",
    "    stmonth = st['acq_date'].apply(lambda x: x.month)\n",
    "    st2 = st[(stmonth == 11) | (stmonth == 12) | (stmonth == 1) | (stmonth == 2)]\n",
    "    st2['acq_date']=st2['acq_date'].apply(lambda x:x.strftime('%Y-%m-%d'))\n",
    "    st2.to_file('sort'+ str(name)+'.shp',\n",
    "            driver='ESRI Shapefile',\n",
    "            encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 火灾情况分析一下\n",
    "# 打开源文件\n",
    "import geopandas as gpd\n",
    "dates = []\n",
    "for name in range(2000,2021):\n",
    "    st = gpd.read_file('Pro_vic/'+ str(name)+'.shp')\n",
    "    dates=dates+list(st.acq_date)\n",
    "\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "dates = [datetime.strptime(x, \"%Y-%m-%d\") for x in dates]\n",
    "dates = pd.Series(dates)\n",
    "df = pd.DataFrame(dates,columns=['date'])\n",
    "df[\"year\"] = df[\"date\"].apply(lambda x: x.year)\n",
    "df[\"month\"] = df[\"date\"].apply(lambda x: x.month)\n",
    "mc = df.groupby([\"month\"]).count()\n",
    "yc = df.groupby([\"year\"]).count()\n",
    "\n",
    "dates.to_csv('dates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 火灾情况简单可视化\n",
    "# 以下部分切换出docker环境，因为环境里没有字体，而我不想配\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "df = pd.read_csv('dates.csv',index_col=0)\n",
    "df.columns=['date']\n",
    "# dates = [datetime.strptime(x, \"%Y-%m-%d\") for x in dates]\n",
    "df['date'] = df['date'].apply(lambda x: datetime.strptime(x, \"%Y-%m-%d\"))\n",
    "df[\"year\"] = df[\"date\"].apply(lambda x: x.year)\n",
    "df[\"month\"] = df[\"date\"].apply(lambda x: x.month)\n",
    "mc = df.groupby([\"month\"]).count()\n",
    "yc = df.groupby([\"year\"]).count()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "plt.rc('font',family='Times New Roman')\n",
    "figprops = dict(figsize=(12, 3), dpi=300)\n",
    "\n",
    "fig = plt.figure(**figprops)\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.bar(range(2000,2000+len(yc['month'])),yc['month'])\n",
    "ax1.set_title('Annual Statistics')\n",
    "ax1.set_xticks(range(2000,2020,3))\n",
    "\n",
    "ax1.xaxis.set_major_formatter(mtick.FormatStrFormatter('%d'))\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "bara1 = ax2.bar(range(1,13),mc['year'],color=['#90EE90'])\n",
    "bara2 = ax2.bar(range(1,13),mc['year'],color=['#5F9EA0'])\n",
    "bara3 = ax2.bar(range(1,13),mc['year'],color=['#F4A460'])\n",
    "bara4 = ax2.bar(range(1,13),mc['year'],color=['#CD5C5C','#CD5C5C','#F4A460','#F4A460','#F4A460','#5F9EA0','#5F9EA0','#5F9EA0','#90EE90','#90EE90','#90EE90','#CD5C5C'])\n",
    "ax2.set_title('Monthly Statistics')\n",
    "ax2.set_xticks(range(1,13))\n",
    "ax2.set_xticklabels(['Jan','Feb','Mar','Apr','May','Jun','Jul','Agu','Sept','Oct','Nov','Dec'])\n",
    "ax2.legend(handles=[bara4,bara3,bara2,bara1], labels=['DJF', 'MAM','JJA','SON'],loc='best')\n",
    "plt.show()\n",
    "fig.savefig('statistics.pdf',format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并到一个shp中，并且清洗不必要的变量\n",
    "st2 = gpd.read_file('sort2000.shp')\n",
    "for name in range(2001,2021):\n",
    "    fire_gdf = gpd.read_file('sort'+ str(name)+'.shp')\n",
    "    st2 = st2.append(fire_gdf)\n",
    "st = st2\n",
    "a = list(st2.columns)\n",
    "st = st.drop(columns=a[16:])\n",
    "# st = st.drop(columns=a[-38:])\n",
    "# st = st.drop(columns=a[0:2])\n",
    "# a = list(st.columns)\n",
    "# st = st.drop(columns=a[20:120])\n",
    "# a = list(st.columns)\n",
    "# st = st.drop(columns=a[-5:])\n",
    "st['geometry']=st2['geometry']\n",
    "st.to_file('all.shp',\n",
    "        driver='ESRI Shapefile',\n",
    "        encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "from osgeo import gdal,osr,ogr\n",
    "names = ['dmc','dc','ffmc','isi']\n",
    "names = ['fwi','fdi','kbdi']\n",
    "for name in names:\n",
    "    datafile = \"meteo_vic/\"+name+\".nc\"\n",
    "    nc_data_obj = nc.Dataset(datafile)\n",
    "    Lon = nc_data_obj.variables['lon'][:]\n",
    "    Lat = nc_data_obj.variables['lat'][:]\n",
    "    data = np.array(nc_data_obj.variables[name][:])\n",
    "    b = np.mean(data,axis=0)\n",
    "    #影像的左上角和右下角坐标\n",
    "    LonMin,LatMax,LonMax,LatMin = [Lon.min(),Lat.max(),Lon.max(),Lat.min()] \n",
    "\n",
    "    #分辨率计算\n",
    "    N_Lat = len(Lat) \n",
    "    N_Lon = len(Lon)\n",
    "    Lon_Res = (LonMax - LonMin) /(float(N_Lon)-1)\n",
    "    Lat_Res = (LatMax - LatMin) / (float(N_Lat)-1)\n",
    "\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    out_tif_name = 'meteo_vic/'+name+'.tif'\n",
    "    out_tif = driver.Create(out_tif_name,N_Lon,N_Lat,1,gdal.GDT_Float32) \n",
    "\n",
    "    # 设置影像的显示范围\n",
    "    #-Lat_Res一定要是-的\n",
    "    geotransform = (LonMin,Lon_Res, 0, LatMax, 0, -Lat_Res)\n",
    "    out_tif.SetGeoTransform(geotransform)\n",
    "\n",
    "    #获取地理坐标系统信息，用于选取需要的地理坐标系统\n",
    "    srs = osr.SpatialReference()\n",
    "    srs.ImportFromEPSG(4326) # 定义输出的坐标系为\"WGS 84\"，AUTHORITY[\"EPSG\",\"4326\"]\n",
    "    out_tif.SetProjection(srs.ExportToWkt()) # 给新建图层赋予投影信息\n",
    "\n",
    "    #数据写出\n",
    "    out_tif.GetRasterBand(1).WriteArray(b) # 将数据写入内存，此时没有写入硬盘\n",
    "    out_tif.FlushCache() # 将数据写入硬盘\n",
    "    out_tif = None # 注意必须关闭tif文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 火灾点shapefile转tiff\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "st2 = gpd.read_file('all.shp')\n",
    "plt.figure()\n",
    "src = rio.open('victiff/f_water.tif')\n",
    "profile = src.profile\n",
    "bounds = src.bounds\n",
    "shape = src.shape\n",
    "data = src.read(1)\n",
    "xedges = np.linspace(bounds[0], bounds[2], shape[1])\n",
    "yedges = np.linspace(bounds[1], bounds[3], shape[0])\n",
    "H, xedges, yedges = np.histogram2d(st2.geometry.x,st2.geometry.y, bins=(shape[1],shape[0]))\n",
    "# print(H)\n",
    "H = H.T\n",
    "H = np.flipud(H)\n",
    "H[np.isnan(data)] = np.nan\n",
    "X, Y = np.meshgrid(xedges, yedges)\n",
    "# plt.pcolormesh(X, Y, H)\n",
    "plt.imshow(H)\n",
    "plt.colorbar()\n",
    "\n",
    "with rio.open('victiff/occur.tif', 'w', **profile) as dst:\n",
    "     dst.write(H, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# river和water合并\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "src_river = rio.open('victiff/f_rive.tif')\n",
    "src_water = rio.open('victiff/f_wate.tif')\n",
    "river = src_river.read(1)\n",
    "water = src_water.read(1)\n",
    "river[river==src_river.nodata] = np.nan\n",
    "water[water==src_water.nodata] = np.nan\n",
    "profile = src_water.profile\n",
    "w = np.array([river,water])\n",
    "a=np.min(w,0)\n",
    "\n",
    "with rio.open('victiff/example.tif', 'w', **profile) as dst:\n",
    "     dst.write(a, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读victiff 所有栅格\n",
    "import numpy as np\n",
    "import rasterio as rio\n",
    "# import geopandas as gpd\n",
    "# names = ['est_occur','dem','disest_r_p','disest_r_s','disest_railway','disest_w','evi','landcover','ndvi','nw','slope']\n",
    "\n",
    "\n",
    "\n",
    "def read_Data(names):\n",
    "    bands = []\n",
    "    datas = []\n",
    "    src = rio.open('victiff/pick_mask1.tif')\n",
    "    data = src.read(1)\n",
    "    data = data.astype(np.double)\n",
    "    data[data==src.nodata] = np.nan\n",
    "    emptys = np.isnan(data)\n",
    "    for name in names:\n",
    "        src = rio.open('victiff/'+name+'.tif')\n",
    "        data = src.read(1)\n",
    "        data = data.astype(np.double)\n",
    "        data[data==src.nodata] = np.nan\n",
    "        emptys[np.isnan(data)] = True\n",
    "        # break\n",
    "        \n",
    "        bands.append(data)\n",
    "        # data = data[~np.isnan(data)]\n",
    "        # print(data.shape)\n",
    "    #     datas.append(data)\n",
    "    bands = np.array(bands)\n",
    "    # datas = np.array(datas)\n",
    "    for i in range(bands.shape[0]):\n",
    "        band = bands[i,:,:]\n",
    "        band[emptys] = np.nan\n",
    "        bands[i,:,:] = band\n",
    "        data = band[~np.isnan(band)]\n",
    "        datas.append(data)\n",
    "    datas = np.array(datas)\n",
    "    return bands,datas,emptys\n",
    "\n",
    "def vif_corr(datas,names,dropname = None):\n",
    "    import pandas as pd\n",
    "    from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "    import numpy as np\n",
    "    from statsmodels.tools.tools import add_constant\n",
    "    import matplotlib.pyplot as plt, seaborn\n",
    "    # X = datas#[1:,:]\n",
    "    X = pd.DataFrame(datas.T,columns = names)\n",
    "    if len(dropname) != 0:\n",
    "        for dropn in dropname:\n",
    "            X = X.drop(axis=1, columns=dropn)\n",
    "    X2 =add_constant(X)\n",
    "\n",
    "    # 当VIF<10,说明不存在多重共线性；当10<=VIF<100,存在较强的多重共线性，当VIF>=100,存在严重多重共线性\n",
    "    VIF_list = [variance_inflation_factor(X2,i) for i in range(X2.shape[1])]\n",
    "    for VIF in VIF_list:\n",
    "        print(VIF)\n",
    "    df_corr = X.corr()\n",
    "    fig = plt.figure(dpi=200)\n",
    "    mask = np.zeros_like(df_corr)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "    seaborn.set(context='notebook', style='ticks', font_scale=0.5)\n",
    "    with seaborn.axes_style(\"white\"):\n",
    "        ax = seaborn.heatmap(df_corr, center=0, annot=True, cmap=\"vlag\",mask=mask, vmax=1,vmin=-1, square=True, xticklabels=X.columns, yticklabels=X.columns)\n",
    "    plt.show()\n",
    "    return VIF_list,df_corr,fig\n",
    "\n",
    "def model_p_predict(datas,names,dropname = None):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import statsmodels.api as sm\n",
    "    from statsmodels.formula.api import ols #加载ols模型\n",
    "    from statsmodels.formula.api import poisson\n",
    "    import matplotlib.pyplot as plt\n",
    "    from statsmodels.tools.tools import add_constant\n",
    "    from sklearn import metrics\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    X3 = pd.DataFrame(datas.T,columns=names)\n",
    "    if len(dropname) != 0:\n",
    "        for dropn in dropname:\n",
    "            X3 = X3.drop(axis=1, columns=dropn)\n",
    "    X3['forest'] = X3['landcover2'].apply(lambda x: 1 if x==1 else 0)\n",
    "    X3['shrublands'] = X3['landcover2'].apply(lambda x: 1 if x==2 else 0)\n",
    "    X3['savannas'] = X3['landcover2'].apply(lambda x: 1 if x==3 else 0)\n",
    "    X3['grasslands'] = X3['landcover2'].apply(lambda x: 1 if x==4 else 0)\n",
    "    X3['wetlands'] = X3['landcover2'].apply(lambda x: 1 if x==5 else 0)\n",
    "    # X3['croplands'] = X3['landcover'].apply(lambda x: 1 if x==6 else 0)\n",
    "    X3 = X3.drop(axis=1, columns='landcover2')\n",
    "    # total auc\n",
    "    grouptable = X3\n",
    "\n",
    "    ntable = (grouptable-grouptable.min())/(grouptable.max()-grouptable.min())\n",
    "    y = grouptable['occur']\n",
    "    x = ntable.drop(axis=1, columns='occur')\n",
    "    x = add_constant(x)\n",
    "    selected = list(ntable.columns)\n",
    "    selected.remove('occur')\n",
    "    selected = list(selected)\n",
    "\n",
    "    formula = \"occur ~ {}\".format(\n",
    "                ' + '.join(selected))\n",
    "    auc_ts = []\n",
    "    nowpars = []\n",
    "    alls = []\n",
    "    auc0 = 0\n",
    "    for i in range(10):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,train_size=0.8)\n",
    "        # 多元线性回归\n",
    "        # model = sm.GLM(y_train,x_train,family=sm.families.Poisson())\n",
    "        # model = sm.GLM(y_train,x_train,family=sm.families.Poisson())\n",
    "        model = ols(formula,data=x_train)\n",
    "        results = model.fit()\n",
    "        paramet = results.params\n",
    "        nowpars.append(paramet)\n",
    "        pred = model.predict(paramet, x_test)\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_test, pred, pos_label=2)\n",
    "        auc = metrics.auc(fpr, tpr)\n",
    "        auc_ts.append(results.aic)\n",
    "        # alls = pd.concat([y,y_test])\n",
    "        # alls[y_test.index] = pred\n",
    "        all = model.predict(paramet, x)\n",
    "        alls.append(all)\n",
    "        if auc > auc0:\n",
    "            b_model = results\n",
    "        # break\n",
    "    return alls, auc_ts, nowpars,b_model\n",
    "def model_m_predict(datas,names,dropname = None):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import statsmodels.api as sm\n",
    "    from statsmodels.formula.api import ols #加载ols模型\n",
    "    from statsmodels.formula.api import poisson\n",
    "    import matplotlib.pyplot as plt\n",
    "    from statsmodels.tools.tools import add_constant\n",
    "    from sklearn import metrics\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    X3 = pd.DataFrame(datas.T,columns=names)\n",
    "    if len(dropname) != 0:\n",
    "        for dropn in dropname:\n",
    "            X3 = X3.drop(axis=1, columns=dropn)\n",
    "    X3['forest'] = X3['landcover2'].apply(lambda x: 1 if x==1 else 0)\n",
    "    X3['shrublands'] = X3['landcover2'].apply(lambda x: 1 if x==2 else 0)\n",
    "    X3['savannas'] = X3['landcover2'].apply(lambda x: 1 if x==3 else 0)\n",
    "    X3['grasslands'] = X3['landcover2'].apply(lambda x: 1 if x==4 else 0)\n",
    "    X3['wetlands'] = X3['landcover2'].apply(lambda x: 1 if x==5 else 0)\n",
    "    # X3['croplands'] = X3['landcover'].apply(lambda x: 1 if x==6 else 0)\n",
    "    X3 = X3.drop(axis=1, columns='landcover2')\n",
    "    # total auc\n",
    "    grouptable = X3\n",
    "\n",
    "    ntable = (grouptable-grouptable.min())/(grouptable.max()-grouptable.min())\n",
    "    y = grouptable['occur']\n",
    "    x = ntable.drop(axis=1, columns='occur')\n",
    "    x = add_constant(x)\n",
    "    auc_ts = []\n",
    "    nowpars = []\n",
    "    alls = []\n",
    "    auc0 = 0\n",
    "    for i in range(10):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,train_size=0.8)\n",
    "        # possion回归\n",
    "        # model = sm.GLM(y_train,x_train,family=sm.families.Poisson())\n",
    "        model = sm.GLM(y_train,x_train,family=sm.families.Poisson())\n",
    "        results = model.fit()\n",
    "        paramet = results.params\n",
    "        nowpars.append(paramet)\n",
    "        pred = model.predict(paramet, x_test, linear=False)\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_test, pred, pos_label=2)\n",
    "        auc = metrics.auc(fpr, tpr)\n",
    "        auc_ts.append(results.aic)\n",
    "        # alls = pd.concat([y,y_test])\n",
    "        # alls[y_test.index] = pred\n",
    "        all = model.predict(paramet, x, linear=False)\n",
    "        alls.append(all)\n",
    "        if auc > auc0:\n",
    "            b_model = results\n",
    "        # break\n",
    "    return alls, auc_ts, nowpars,b_model\n",
    "def save_figs(alls,emptys,name):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import rasterio as rio\n",
    "    alls = np.array(alls)\n",
    "    src = rio.open('victiff/f_roads.tif')\n",
    "    band = np.full(src.shape, np.nan)\n",
    "    profile = src.profile\n",
    "    a = np.mean(alls,axis=0)\n",
    "    band[~emptys] = a\n",
    "    plt.imshow(band)\n",
    "    plt.colorbar()\n",
    "    with rio.open('outputs/mean'+name+'.tif', 'w', **profile) as dst:\n",
    "        dst.write(band, 1)\n",
    "    b = np.std(alls,axis=0)\n",
    "    band[~emptys] = b\n",
    "    with rio.open('outputs/std'+name+'.tif', 'w', **profile) as dst:\n",
    "        dst.write(band, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主程序\n",
    "# ,'Pick_dmc','Pick_ffmc','Pick_isi'\n",
    "# ,'Pick_dmc','Pick_ffmc','Pick_isi','Pick_fwi','Pick_fdi','Pick_kbdi'\n",
    "names = ['occur','Pick_dem','f_roads','f_roadp','f_rail','f_water','f_evi','f_ndvi','Pick_nw','Pick_slope','landcover2','f_wui','Pick_dc']\n",
    "# 读取数据\n",
    "bands,datas,emptys = read_Data(names)\n",
    "# 检查多元共线性\n",
    "VIF_list,df_corr,fig_corr = vif_corr(datas, names, dropname =['landcover2'])\n",
    "# 预测\n",
    "alls, auc_ts, nowpars, b_model = model_p_predict(datas,names, dropname =['f_evi','Pick_slope'])\n",
    "alls2, auc_ts2, nowpars2, b_model2 = model_m_predict(datas,names, dropname =['f_evi','Pick_slope'])\n",
    "save_figs(alls2, emptys, '_ols')\n",
    "save_figs(alls, emptys, '_pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 整理AIC summary\n",
    "import pandas as pd\n",
    "stats = [np.mean(auc_ts),np.min(auc_ts),np.max(auc_ts),np.max(auc_ts)-np.min(auc_ts),np.median(auc_ts),np.std(auc_ts),np.var(auc_ts)]\n",
    "stats = pd.DataFrame(stats,index=['MEAN','MIN','MAX','RANGE','MEDIAN','STD','VAR'])\n",
    "stats.to_csv('stats5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 折刀估计\n",
    "def estimate_jack(datas,names):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import statsmodels.api as sm\n",
    "    from statsmodels.formula.api import ols #加载ols模型\n",
    "    from statsmodels.formula.api import poisson\n",
    "    import matplotlib.pyplot as plt\n",
    "    from statsmodels.tools.tools import add_constant\n",
    "    from sklearn import metrics\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import statsmodels.formula.api as smf\n",
    "    from statsmodels.formula.api import ols\n",
    "    p_w = []\n",
    "    p_o = []\n",
    "    p_o2=[]\n",
    "    p_w2=[]\n",
    "    names3 = names[1:]\n",
    "    names3.remove('f_evi')\n",
    "    names3.remove('Pick_slope')\n",
    "    names3.remove('landcover2')\n",
    "    X3 = pd.DataFrame(datas.T,columns=names)\n",
    "    X3 = X3.drop(axis=1, columns='Pick_slope')\n",
    "    X3 = X3.drop(axis=1, columns='f_evi')\n",
    "    X3 = X3.drop(axis=1, columns='landcover2')\n",
    "    # total auc\n",
    "    grouptable = X3\n",
    "    y = grouptable['occur']\n",
    "    x = grouptable.drop(axis=1, columns='occur')\n",
    "    xp = add_constant(x)\n",
    "    selected = list(grouptable.columns)\n",
    "    selected.remove('occur')\n",
    "    selected = list(selected)\n",
    "\n",
    "    formula = \"occur ~ {}\".format(\n",
    "            ' + '.join(selected))\n",
    "\n",
    "    model = sm.GLM(y,xp,family=sm.families.Poisson())\n",
    "    results = model.fit()\n",
    "    p_t = results.aic\n",
    "\n",
    "    model2 = ols(formula,data=grouptable)\n",
    "    results2 = model2.fit()\n",
    "    p_t2 = results2.aic\n",
    "    for name in names3:\n",
    "        grouptable = X3\n",
    "        x2 = pd.DataFrame(grouptable[name])\n",
    "        grouptable = grouptable.drop(axis=1, columns=name)\n",
    "        y = grouptable['occur']\n",
    "        x2['occur'] = y\n",
    "        x = grouptable\n",
    "        xp = add_constant(x)\n",
    "        xp2 = add_constant(x2)\n",
    "        \n",
    "        # auc without \n",
    "        selected = list(grouptable.columns)\n",
    "        selected.remove('occur')\n",
    "        selected = list(selected)\n",
    "\n",
    "        formula = \"occur ~ {}\".format(\n",
    "                ' + '.join(selected))\n",
    "        model = sm.GLM(y,xp,family=sm.families.Poisson())\n",
    "        results = model.fit()\n",
    "        p_w.append(results.aic)\n",
    "\n",
    "        model2 = ols(formula,data=x)\n",
    "        results2 = model.fit()\n",
    "        p_w2.append(results.aic)\n",
    "\n",
    "        # auc with only\n",
    "        formula = \"occur ~ {}\".format(name)\n",
    "        model = sm.GLM(y,xp2,family=sm.families.Poisson())\n",
    "        results = model.fit()\n",
    "        p_o.append(results.aic)\n",
    "\n",
    "        model2 = ols(formula,data=x)\n",
    "        results2 = model.fit()\n",
    "        p_o2.append(results.aic)\n",
    "    return p_t,p_t2,p_o,p_w,p_o2,p_w2\n",
    "def draw_jack(p_t,p_t2,p_o,p_w,p_o2,p_w2,name=False):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    ap = [p_o,p_w,p_o2,p_w2]\n",
    "    size = 20\n",
    "    x = np.array(range(0,size,2))\n",
    "\n",
    "    total_width, n = 2, 5\n",
    "    width = total_width / n\n",
    "    x = x - (total_width - width) / 2\n",
    "    plt.Figure(dpi=300,figsize=(8,6))\n",
    "    plt.barh(x[-1]  + 1.5 * width, p_t,  height=width,color='#DCDCDC' ,ls='-',ec='#000000',hatch='/')\n",
    "    plt.barh(x[-1]  + 2.5 * width, p_t2,  height=width,color='#DCDCDC',ls='-',ec='#000000')\n",
    "    plt.barh(x[:-1] + 0.5 * width, p_o, height=width, label='PR AIC with only',color='#FFFFFF',ls='-',ec='#000000',hatch='/')\n",
    "    plt.barh(x[:-1] + 1.5 * width, p_w, height=width, label='PR AIC without',color='#A9A9A9',ls='-',ec='#000000',hatch='/')\n",
    "    plt.barh(x[:-1] + 2.5 * width, p_o2, height=width, label='MLR AIC with only',color='#FFFFFF',ls='-',ec='#000000')\n",
    "    plt.barh(x[:-1] + 3.5 * width, p_w2, height=width, label='MLR AIC without',color='#A9A9A9',ls='-',ec='#000000')\n",
    "    plt.legend(bbox_to_anchor=(1.05,1.0),borderaxespad = 0.)\n",
    "    plt.yticks(range(0,size,2),['Elevation','DRS','DRP','DRR','DW','NDVI','NW','DWUI','DC','Overall'])\n",
    "    if name != False:\n",
    "        plt.savefig(name+'.pdf',format='pdf')\n",
    "    plt.show()\n",
    "\n",
    "p_t,p_t2,p_o,p_w,p_o2,p_w2 = estimate_jack(datas,names)\n",
    "draw_jack(p_t,p_t2,p_o,p_w,p_o2,p_w2,name='AIC')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
